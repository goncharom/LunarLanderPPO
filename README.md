# PPOv1
My first implementation of OpenAI's Proximal Policy Optimization. Still learning
